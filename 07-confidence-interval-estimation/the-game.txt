 1. Как да сме уверени в ефективността на дадена промяна?
 2. Точкови оценки
 3. Интервални оценки
 4. Оценяване на разликата между параметри на извадки от две популации

 ***

  Вече често сме си говорили за термините популация и извадка.  Тежкият
  въпрос, който е нужно да засегнем е, какво всъщност представляват тези
  понятия?  Да, знаем че популацията е цялото, всички наблюдения, които можем
  да имаме, а извадката е част от тях.  Ама, това не е достатъчно - то не ни
  дава и най-малка представа за същността на термините.  Нека подходим по
  друг начин.

  Ако имахме безброй много хора на земята, как щяхме да разберем средно колко
  харчи на месец всеки от тях?  Ами, това ще е задача клоняща към
  невъзможното.  Най-малкото, дори да се движихме със скоростта на светлината,
  ние пак не бихме могли да обиколим безкрайността.  Какво ни остава, тогава?
  Ами, остава ни това да вземем голямо количество случайни хора, да ги
  разпитаме колко харчат на месец и, на базата на тия данни, да си направим
  заключение за това колко харчат на месец всичките безброй много хора.

  Нека сега се върнем към реалността.  Във ФМИ се намира едно нещо наречено
  УЦИКТ.  Част от това нещо поддържа тъй обичаната от всички нас система СУСИ.
  Един от хората, които работят по СУСИ иска да разбере колко бързо системата
  връща избираемите дисциплини за даден курс и дадена специалност.  Има
  проблем, обаче, не знаем колко са всички заявки към СУСИ, защото все още не
  сме стигнали до момента в бъдещето, когато системата ще спре да функционира.
  Ние просто имаме някакви данни до сегашното ни положение и искаме на базата
  на тях да направим заключение за бързодействието на СУСИ.  Облечено в
  термини - популацията ни представлява всичките заявки направени към СУСИ до
  сега плюс тези, които ще бъдат осъществени в бъдеще, а извадката ни са
  заявките, спрямо които ще си направим заключение за бързодействието на 
  системата.  Също така, много е важно е да отбележим, че смятаме заявките в
  бъдеще да се осъществяват при същото състояние на системата - тоест, СУСИ не
  се обновява и не става нито по-бърза, нито по-бавна.

  Избираме си времената от 100 заявки за взимане на избираеми дисциплини от
  СУСИ в рамките на една година.  Много е важно те да са в колкото се може
  по-случайни дни от годината.  Искаме да оценим средното време за обработване
  на дадена заявка от СУСИ.  Това се прави лесно - просто смятаме
  математическото очакване на тези 100 заявки.  Трябва да вземем предвид
  обаче, че работим с извадка от всички заявки - полученото средно не е
  средното на цялата популация.  Казано с други думи, средното на извадката е
  в някаква грешка от средното на цялата популация.  Ние искаме да изчислим по
  някакъв начин тази грешка и да сме много уверени в нея.  Сега ще го
  направим.

  Знаем, че средното на дадена извадка е нормално разпределено за големи
  стойности на `n`.  Следователно, можем да изчислим следната стойност:

                                mean(X) - mu
                          z = -----------------
                               sigma / sqrt(n)

  Където `sigma` e стандартното отклонение на популацията.  Ние обаче не знаем
  какво е това стандартно отклонение, защото не разполагаме с всички данни за
  времената на отговор на заявка към СУСИ.  Поради тая причина трябва да
  модифицираме начинът, по който изчисляваме апроксимацията си.  Ще изчислим
  следната стойност:

                                mean(X) - mu
                          t = ----------------
                                 s / sqrt(n)

  Където `s` е стандартното отклонение на извадката от данни.  Тази статистика
  се нарича t-статистика и е валидна за следните ситуации:
    1. Ако `n` е малко и Xi са нормално разпределени.  Тогава тази стойност
        следва t-разпределение с n-1 степени на свобода
    2. Ако `n` е голямо, прилагаме ЦГТ и стойността следва нормално
        разпределение

  Така, n е голямо, така че можем да кажем, че t следва нормално
  разпределение.  Питаме се какъв е интервалът, в който има 95% вероятност да
  се намира средното на популацията?  Математически изразено, това отговаря на
  следното:

                      P(-t_0.025 < t < t_0.025)

                                  <=>

                              mean(X) - mu
                P(-t_0.025 < --------------- < t_0.025)
                               s / sqrt(n)

  Което след опростяване е:

    P(mean(X) - t_0.025 * (s / sqrt(n)) < mu < mean(X) + t_0.025 * (s / sqrt(n)))

  Отговорът на този израз ще ни даде интервалът, за който средното на
  популацията `mu`, лежи в 95% от случаите.  Тоест, за нашето изчислено средно
  на извадката, ние ще получим интервал, в който има 95% вероятност да лежи
  средното на популацията.  Какво значи 95% вероятност?  Ами това значи, че
  ако сме взели 20 набора от по 100 случайни заявки към СУСИ, поне 1 от тия
  набори няма да представя реалността - интервалът, който изчисляваме на базата
  на него реално няма да включва популационното средно.

  Сега е време за малко терминология.

  Извадъчното средно, което изчислихме (mean(X)) се нарича точкова оценка на
  извадката.  То е определена стойност, около която смятаме, че се намира
  съответната оценка на популацията.

  Интервалът, който получаваме, се нарича доверителен интервал.  Той ни дава
  интервалът около точковата оценка, в който с дадена сигурност можем да
  кажем, че се намира съответната оценка на популацията.

  Стойността `t_0.025 * (s/sqrt(n))` се нарича стандартна грешка.

  Имайки тези знания, можем да ги приложим за да разберем какво средно време
  за отговор да очакваме от СУСИ при заявка от наша страна за взимане на
  избираеми дисциплини:

    > source("susi.R")
    > mean_response_time = mean(response_times)
    > sd_response_times = sd(response_times)
    > margin_of_error = 1.96*(sd_response_times / sqrt(length(response_times)))

  Освен от бързината на отговор на СУСИ за избираемите дисциплини, ние се
  интересуваме и от мнението на студентите за това колко е бърза системата.
  Направили сме анкета сред 100 студенти, където сме ги питали дали са доволни
  от скоростта на системата.  81% са отговорили с "Не".  Въпросът е, доколко е
  вероятно всички студенти да мислят така?

  Тук оценката ни е процентът хора, които са дали даден отговор на анкетата.
  В случая, 81% от запитаните са отговорили с "Не".  Искаме да видим какъв е
  диапазонът на грешка на тази оценка:

    > phat = 0.81; qhat = 1-phat
    > n = 100
    > margin_of_error = 1.96 * (sqrt(phat*qhat) / sqrt(n))

  В случая, стандартната грешка се изчислява по следната формула:

                      sqrt(phat * qhat)
                     -------------------
                          sqrt(n)

  Виждаме, че истинската стойност на p може да бъде малка, колкото 0.74 или
  голяма колкото 0.88.  Това показва, че когато правим оценка за пропорция, е
  нужно да работим с доста големи извадки за да сме точни.  Но има вероятност
  истинската стойност на p въобще да не е в този интервал.  В случая, тази
  вероятност е 5%, защото сме направили 95%-тен доверителен интервал.  Това ще
  рече, че ако анкетираме 20 пъти различни групи от по 100 човека, 1 от тези
  групи ще ни даде грешни заключения за истинската стойност за p.  За да решим
  този проблем, трябва да вдигнем процента на доверие в интервала.  Вдигайки
  процента на доверие, обаче, ние увеличаваме размера на интервала.
  Увеличавайки размера на интервала, заключението ни става по-неточно.  Така
  че трябва да определим, спрямо данните ни, до колко можем да разпъваме
  интервала на доверие.  Шансът за грешка се бележи с alpha, а когато правим
  доверителен интервал, казваме че той е (1 - alpha)%-тен доверителен
  интервал.  В случая с 95%-ния интервал, alpha е 5%.

  Естествено, R може да направи доверителен интервал за дадена пропорция:

    > prop.test(81, 100, conf.level=0.95)

  След като видяли резултатите от анкетата, хората поддържащи СУСИ решили, че
  е нужно да направят нещо по въпроса за бързодействието на системата.  Те
  мислили и мислили, и колкото повече мислили, толкова повече код рязали.
  Накрая СУСИ постигнала завидни резултати.  Те били измерени и описани, а
  след това било нужно да се разбере доколко по-бърза е новата система.

  Тук вече е нужно да се научим как можем да сравняваме две статистики.
  Искаме да видим дали времената за отговор след подобрението на СУСИ се
  различават от времената за отговор преди подобрението на СУСИ.  Един от
  начините да отчетем такава разлика, е да сравним математическите очаквания
  на двете статистики.  Това ще направим по начин подобен на конструирането на
  доверителни интервали за средно на дадена извадка.

  Та, ако X1 е извадката от времена за отговор преди подобрението, а X2 е
  извадката от времена за отговор след подобрението, `mean(X1) - mean(X2)` ще
  ни даде точкова оценка за разликата между средните на двете популации.  

  Дотук добре, обаче трябва да се сдобием и с интервала, в който можем с
  някаква сигурност да очакваме, че разликата между двете популации ще се
  намира.  За целта, първо трябва да изчислим нашата стандартна грешка (SE).
  Тя се смята по формулата:

                                   s1^2     s2^2
                        SE = sqrt(------ + ------),
                                    n1       n2

  където s1, s2 са стандартните отклонения на извадката от отговори преди
  подобрението и извадката от отговори след подобрението, респективно.  n1, n2
  са размерите на извадката от отговори преди подобрението и извадката от
  отговори след подобрението.  Понеже знаем, че n1 и n2 са големи числа, можем
  да използваме стандартните отклонения на извадката, при положение, че не
  знаем стандратното отклонение на популацията.

  Искаме да сме доста уверени в преценката си, за това ще конструираме 99%-тен
  доверителен интервал:

                      (mean(X1) - mean(X2)) +- 2.58 * SE

  Нека видим какво ще се случи като приложим тези сметки върху данните от
  СУСИ:

    > source("susi.R")
    > mean_diff_response_time =
    +   mean(response_times) - mean(new_response_times)
    > se_response_time = var(response_times) / length(response_times)
    > se_new_response_time = var(new_response_times) /
    +   length(new_response_times)
    > margin_of_error = 2.58 * sqrt(se_response_time + se_new_response_time)

  Виждаме, че подобрената СУСИ е по-бърза със средно ~4 +- ~2 секунди.  Спрямо
  доверителния ни интервал, най-бавната заявка е с ~2 секунди по-бърза от тази
  на старата версия на системата.  Това ще рече, че сме 99% сигурни в
  твърдението си, че новото СУСИ изпълнява заявките към него доста по-бързо.
  Естествено, отново има 1% вероятност да сме сгрешили какъв е доверителният
  ни интервал.  Забележете, че ако тази грешка е налице, реалната система може
  или да е много по-бърза от измереното, или всъщност да е по-бавна.
  Забележете, също така, че стандартната грешка ни позволява да сравняваме
  извадки с различен брой наблюдения.

  Дотук добре, ама това че новата СУСИ е по-бърза спрямо тия данни не означава,
  че хората, които я използват ще са доволони от бързодействието ѝ.  Нека да
  видим какъв е резултатът от нова проведена анкета сред учащите в СУ.  Отново
  са били запитани 100 човека.  От тях 67 отговорили, че не са доволни от
  скоростта на системата.  Виждаме, че този път по-малък процент хора са
  изразили недоволството си.  Въпреки това, ние не разполагаме с всичките
  данни и не бива само на базата на тоя резултат да заключим, че студентите
  ползват подобрената СУСИ с по-голямо удоволствие.  Нека направим оценка за
  разликата между отговорите в предишната и отговорите в тази анкета.

  Точковата оценка за разликата е `p1 - p2`, където p1 е пропорцията хора,
  отговорили с "Не" на първата анкета, а p2 е пропорцията хора, отговорили с
  "Не" на втората анкета.

  Стандартната ни грешка ще се конструира спрямо формулата:

                                 p1*q1     p2*q2
                      SE = sqrt(------- + -------),
                                   n1        n2

  където q1 = (1-p1), q2 = (1-p2), а n1 и n2 съответно са хората включени в
  първата и втората анкета.

  В крайна сметка, интервалът, в който попадат 99% от случаите е този:

                          (p1 - p2) +- 2.58 * SE

  Нека сметнем тия работи в R:

    > prop_before = 0.81
    > prop_after = 0.67
    > prop_diff = prop_before - prop_after
    > se_before = prop_before * (1 - prop_before) / 100
    > se_after = prop_after * (1 - prop_after) / 100
    > margin_of_error = 2.58 * sqrt(se_before + se_after)

  Виждаме, че най-голямата разлика стига до ~0.3, което ще рече, че в
  най-добрия случай, половината от всички използващи СУСИ ще са доволни от
  бързодействието на системата.  Най-малката разлика е -0.017, което ще рече
  че има възможност всички хора да са малко по-недоволни от новата система в
  сравнение със старата.  Поради тая причина бе нужно да конструираме
  доверителния интервал, въпреки очевидната разлика в резултатите от двете
  анкети - видяхме, че има случай, в който тази анкета може да ни е довела до
  грешен извод.  Дори има 1% вероятност реалната разлика между пропорциите
  хора, които смятат, че старата СУСИ е по-бавна от новата СУСИ, да е извън
  нашия доверителен интервал.
