 1. Как да сме уверени в ефективността на дадена промяна?
 2. Точкови оценки
 3. Интервални оценки
 4. Оценяване на разликата между параметри на извадки от две популации

 ***

  Вече често сме си говорили за термините популация и извадка.  Тежкият
  въпрос, който е нужно да засегнем е, какво всъщност представляват тези
  понятия?  Да, знаем че популацията е цялото, всички наблюдения, които можем
  да имаме, а извадката е част от тях.  Ама, това не е достатъчно - то не ни
  дава ни най-малка представа за същността на термините.  Нека подходим по
  друг начин.

  Ако имахме безброй много хора на земята, как щяхме да разберем средно колко
  харчи на месец всеки от тях?  Ами, това ще е задача клоняща към
  невъзможното.  Най-малкото, дори да се движихме със скоростта на светлината,
  ние пак не бихме могли да обиколим безкрайността.  Какво ни остава, тогава?
  Ами, остава ни това да вземем голямо количество случайни хора, да ги
  разпитаме колко харчат на месец и, на базата на тия данни, да си направим
  заключение за това колко харчат на месец всичките безброй много хора.

  Нека сега се върнем към реалността.  Във ФМИ се намира едно нещо наречено
  УЦИКТ.  Част от това нещо поддържа тъй обичаната от всички нас система СУСИ.
  Един от хората, които работят по СУСИ иска да разбере колко бързо системата
  връща избираемите дисциплини за даден курс и дадена специалност.  Има
  проблем, обаче, не знаем колко са всички заявки към СУСИ, защото все още не
  сме стигнали до момента в бъдещето, когато системата ще спре да функционира.
  Ние просто имаме някакви данни до сегашното ни положение и искаме на базата
  на тях да направим заключение за бързодействието на СУСИ.  Облечено в
  термини - популацията ни е всичките заявки направени към СУСИ до сега плюс
  тези, които ще бъдат осъществени в бъдеще, а извадката ни са заявките,
  спрямо които ще си направим заключение за бързодействието на системата.
  Също така, много е важно е да отбележим, че смятаме заявките в бъдеще да се
  осъществяват при същото състояние на системата - тоест, СУСИ не се обновява
  и не става нито по-бърза, нито по-бавна.

  Избираме си времената от 100 заявки за взимане на избираеми дисциплини от
  СУСИ в рамките на една година.  Много е важно те да са в колкото се може
  по-случайни дни от годината.  Искаме да оценим средното време за обработване
  на дадена заявка от СУСИ.  Това се прави лесно - просто смятаме
  математическото очакване на тези 100 заявки.  Трябва да вземем предвид
  обаче, че работим с извадка от всички заявки - полученото средно не е
  средното на цялата популация.  Следователно, средното на извадката е в
  някаква грешка от средното на популацията.  Ние искаме да изчислим по
  някакъв начин тази грешка и да сме много уверени в нея.

  Знаем, че средното на дадена извадка е нормално разпределено за големи
  стойности на `n`.  Следователно, можем да изчислим следната стойност:

          mean(X) - mu
    z = ----------------
          sigma / sqrt(n)

  Където sigma e стандартното отклонение на популацията.  Ние обаче не знаем
  какво е това стандартно отклонение, защото не разполагаме с всички данни за
  времената на отговор на заявка към СУСИ.  Поради тая причина трябва да
  модифицираме начинът, по който изчисляваме апроксимацията си.  Ще изчислим
  следната стойност:

          mean(X) - mu
    t = ----------------
           s / sqrt(n)

  Където `s` е стандартното отклонение на извадката от данни.  Тази статистика
  се нарича t-статистика и е валидна за следните ситуации:
    1. Ако `n` е малко и Xi са нормално разпределени.  Тогава тази стойност
        следва t-разпределение с n-1 степени на свобода
    2. Ако `n` е голямо, прилагаме ЦГТ и стойността следва нормално
        разпределение

  Така, n е голямо, така че можем да кажем, че t следва нормално
  разпределение.  Питаме се какъв е интервалът, в който има 95% вероятност да
  се намира средното на популацията?  Математически изразено, това отговаря на
  следното:

                  mean(X) - mu
    P(-t_0.025 < --------------- < t_0.025)
                   s / sqrt(n)

  Което след опростяване е:

    P(mean(X) - t_0.025 * (s / sqrt(n)) < mu < mean(X) + t_0.025 * (s / sqrt(n)))

  Какво значи да сме уверени в грешката?  Да кажем, че с някакъв голям
  процент вероятност сме убедени в правотата на твърдението си.  От ЦГТ знаем,
  че оценките за данни с някакво неизвестно разпределение са приблизително
  нормално разпределени.  От емпиричното правило пък знаем, че ако имаме 
  приблизително нормално разпределени данни, 95% от наблюдения лежат на 1.96
  стандартни отклонения от средното.  Понеже SE ни дава оценка за реалното 
  стандартно отколонение на нашите данни, 1.96*SE ще ни даде интервала, в
  който можем да сме 95% сигурни, че се намира средното на популацията.

  Вече разполагаме с две стойности - извадъчното средно и допустимата наша
  грешка.  Нека сега приложим наученото в нашия случай:

    > source("susi.R")
    > mean_response_time = mean(response_times)
    > sd_response_times = sd(response_times)
    > margin_of_error = 1.96*(sd_response_times / sqrt(length(response_times)))

  С 95% увереност можем да кажем, че средното време за отговор е:

                    mean_response_time +- SE

  Освен от бързината на отговор на СУСИ за избираемите дисциплини, ние се
  интересуваме и от мнението на студентите за това колко е бърза системата.
  Направили сме анкета сред 100 студенти, където сме ги питали дали са доволни
  от скоростта на системата.  81% са отговорили с "Не".  Въпросът е, доколко е
  вероятно всички студенти да мислят така.

  Тук оценката ни е процентът хора, които са дали даден отговор на анкетата.
  В случая, 81% от запитаните са отговорили с "Не".  Искаме да видим какъв е
  диапазонът на грешка на тази оценка:

    > phat = 0.81; qhat = 1-phat
    > n = 100
    > margin_of_error = 1.96 * (sqrt(phat*qhat) / sqrt(n))

  В случая, стандартната грешка се изчислява по следната формула:

                      sqrt(phat * qhat)
                     -------------------
                          sqrt(n)

  Виждаме, че истинската стойност на p може да бъде малка, колкото 0.73 или
  голяма като 0.88.  Това показва, че когато правим оценка за пропорция, е
  нужно да работим с доста големи извадки за да сме точни.  Но има вероятност
  истинската стойност на p въобще да не е в този интервал.  В случая, тази
  вероятност е 5%, защото сме направили 95%-тен доверителен интервал.  Това ще
  рече, че ако анкетираме 20 пъти различни групи от по 100 човека, 1 от тези
  групи ще ни даде грешни заключения за истинската стойност за p.  За да решим
  този проблем, трябва да вдигнем процента на доверие в интервала.  Вдигайки
  процента на доверие, обаче, ние увеличаваме размера на интервала.
  Увеличавайки размера на интервала, заключението ни става по-неточно.  Така
  че трябва да определим, спрямо данните ни, до колко можем да разпъваме
  интервала на доверие.  Шансът за грешка се бележи с alpha, а когато правим
  доверителен интервал, казваме че той е (1 - alpha)%-тен доверителен
  интервал.  В случая с 95%-ния интервал, alpha е 5%.

  Естествено, R може да направи доверителен интервал за дадена пропорция:

    > prop.test(81, 100, conf.level=0.95)
